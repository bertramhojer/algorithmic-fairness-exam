{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import data_loader, preprocess\n",
    "from model_helper import get_tuned_gamma, train, tune_lambda, plot_lambda_tuning\n",
    "import numpy as np\n",
    "from PCA import project_and_plot_PCA, plot_reconstruction_loss, fair_PCA, corr_plot\n",
    "import pandas as pd\n",
    "from Bootstrap_and_eval import eval, bootstrap_eval_one, plot_violin_metrics_with_ci_single\n",
    "from NN import train_and_evaluate_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do\n",
    "1. Plot lambda with equalized odds as y-axis\n",
    "2. Compute Average shap values for each feature for each model \n",
    "    - Show SHAP to explain a negative and a positive example (force plot)\n",
    "3. Make NN a bit deeper \n",
    "4. Equalized odds 1v1 and 1v4\n",
    "5. Boostrap metrics for each model \n",
    "6. Correlation between protected features and our features (EDA)\n",
    "7. Equalized odds for different income groups (optional)\n",
    "\n",
    "\n",
    "Karl prioritized list: \n",
    "- Do 1 & 3 in todo \n",
    "- Try to find out the preffered size of dataset \n",
    "- Find optimal hyparameters (Lambda, Gamma)\n",
    "- Train the LR models \n",
    "- Evaluate them, with boostrap plot \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriving, splitting and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "processed_data.csv exists. Loading data from file.\n",
      "x_train: 70.00%\n",
      "x_val: 15.00%\n",
      "x_test: 15.00%\n",
      "Num features BEFORE filtering features 54\n",
      "Num features AFTER filtering features 15\n",
      "x_train shape:  (395460, 15)\n",
      "y_train shape:  (84742, 15)\n",
      "All rows in train_groups sum to 1: True\n"
     ]
    }
   ],
   "source": [
    "one_hot_cols = ['Race_American_Indian_Alaska_Native',\n",
    "        'Race_Asian',\n",
    "        'Race_Black_African_American',\n",
    "        'Race_Native_Hawaiian_Pacific_Islander',\n",
    "        'Race_White',\n",
    "        #'Race_Info_Not_Provided',\n",
    "        #'Race_Not_applicable',\n",
    "        #'Race_No_co_applicant', \n",
    "        'Race_White_Latino']\n",
    "one_hot = True\n",
    "df = data_loader(one_hot_cols, num=1000000)\n",
    "\n",
    "# filter columns to only include columns in the features list below\n",
    "features = ['loan_amount_000s', 'loan_type', 'owner_occupancy', \n",
    "       'property_type','applicant_income_000s', 'purchaser_type', 'hud_median_family_income',\n",
    "       'tract_to_msamd_income', 'number_of_owner_occupied_units', \n",
    "       'number_of_1_to_4_family_units', 'race_ethnicity', 'state_code', 'county_code',\n",
    "       'joint_sex', \"minority_population\", 'lien_status']\n",
    "if one_hot:\n",
    "       # remove  'race_ethnicity' from features\n",
    "       features.remove('race_ethnicity')\n",
    "x_train, x_test, y_train, y_test, train_groups, test_groups = preprocess(df, features, one_hot_cols)\n",
    "print(f'All rows in train_groups sum to 1: {np.allclose(np.sum(train_groups, axis=1), 1)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varitions of Logistic Reggression(LR) models "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "betas = np.random.rand(x_train.shape[1])\n",
    "_lambda = None \n",
    "fair_loss_ = 'NO l2'\n",
    "best_gamma = 0.1 # placeholder\n",
    "\n",
    "unfair_preds = train(x_train, y_train, x_test, y_test, train_groups, fair_loss_, best_gamma, lambda_val=1)  # do use l2 regularization here ergo False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal regulazation strength of L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.random.rand(x_train.shape[1])\n",
    "gammas = np.linspace(0.1, 1, 10)\n",
    "best_gamma = get_tuned_gamma(gammas, x_train, y_train, num_folds=5, verbose=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LR With L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.random.rand(x_train.shape[1])\n",
    "_lambda = None \n",
    "fair_loss_ = False\n",
    "\n",
    "unfair_preds = train(x_train, y_train, x_test, y_test, train_groups, best_gamma, fair_loss_) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find regulazation strength of fair loss(lambda)\n",
    "Then train L2 + Fairness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_loss_ = True\n",
    "best_gamma = 0.1\n",
    "performance_metrics = tune_lambda(x_train, y_train, test_groups, train_groups, x_test, y_test, fair_loss_, best_gamma, one_hot_cols=one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vals = [0.001, 0.005, 0.01, 0.05, 0.1, 1]\n",
    "plot_lambda_tuning(performance_metrics, lambda_vals, one_hot_cols=one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.random.rand(x_train.shape[1])\n",
    "_lambda = None \n",
    "fair_loss_ = True\n",
    "\n",
    "unfair_preds = train(x_train, y_train, x_test, y_test, train_groups, fair_loss_, best_gamma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape of x_train, y_train, x_test, y_test, groups,\n",
    "print(\"x_train shape: \", x_train.shape, type(x_train))\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape, type(x_test))\n",
    "print(\"y_test shape: \", y_test.shape, type(y_test))\n",
    "print(\"train groups shape: \", train_groups.shape)\n",
    "print(\"test groups shape: \", test_groups.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair PCA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit PCA components to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pd = pd.DataFrame(x_train, columns=features)\n",
    "x_test_pd = pd.DataFrame(x_test, columns=features)\n",
    "project_and_plot_PCA(x_train_pd, n_components=len(features), size = (25,10),corr_metric='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plot(x_train_pd, 'pearson', train_groups, n_components=len(features), fair=False)\n",
    "corr_plot(x_train_pd, 'pearson', train_groups, n_components=len(features), fair=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_loss(x_train_pd, x_test_pd, len(features), train_groups, fair=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on fair PCA data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_preds, pca_preds, fair_preds = eval(x_train_pd, x_test_pd, y_test, y_train, y_test, train_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gamma = 0.1\n",
    "unfair_preds = train(x_train, y_train, x_test, y_test, train_groups, fair_loss_=False, best_gamma=best_gamma)  # do use l2 regularization here ergo False\n",
    "n_bootstrap = 1000\n",
    "sample_size = 500\n",
    "accuracy_scores, f1_scores, precision_scores, recall_scores = bootstrap_eval_one(unfair_preds, None, y_test, n_bootstrap, sample_size)\n",
    "plot_violin_metrics_with_ci_single(accuracy_scores, f1_scores, precision_scores, recall_scores, confidence_level=0.95)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACK BOX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "x_train_np = np.array(x_val)\n",
    "y_train_np = np.array(y_val)\n",
    "x_test_np = np.array(x_test)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "train_and_evaluate_nn(x_train_np, x_test_np, y_train_np, y_test_np,num_epochs=100, plot_loss=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN trained on fair PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fair, U, explained_variance = fair_PCA(x_train, 15, train_groups)\n",
    "x_test_fair = x_test_np @ U\n",
    "train_and_evaluate_nn(x_train_fair, x_test_fair, y_train_np, y_test_np,num_epochs=100, plot_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

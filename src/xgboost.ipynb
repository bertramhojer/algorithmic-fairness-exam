{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import data_loader, preprocess\n",
    "from PCA import fair_PCA\n",
    "import xgboost as xgb\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "\n",
    "\n",
    "one_hot_cols = ['Race_American_Indian_Alaska_Native', 'Race_Asian', 'Race_Black_African_American', \n",
    "                'Race_Native_Hawaiian_Pacific_Islander', 'Race_White', 'Race_White_Latino']\n",
    "# filter columns to only include columns in the features list below\n",
    "features = ['loan_amount_000s', 'loan_type', 'property_type','applicant_income_000s', \n",
    "            'hud_median_family_income', 'tract_to_msamd_income', \n",
    "            'number_of_owner_occupied_units', 'number_of_1_to_4_family_units', #'race_ethnicity', 'joint_sex', \"minority_population\", 'purchaser_type', \n",
    "            'state_code', 'county_code', 'lien_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "processed_data.csv exists. Loading data from file.\n",
      "x_train: 70.00%\n",
      "x_val: 15.00%\n",
      "x_test: 15.00%\n",
      "Num features BEFORE filtering features 54\n",
      "Num features AFTER filtering features 11\n",
      "x_train shape:  (395460, 11)\n",
      "y_train shape:  (84742, 11)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1_000_000\n",
    "df = data_loader(one_hot_cols, num=num_samples)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, train_groups, val_groups, test_groups = preprocess(df, features, one_hot_cols)\n",
    "\n",
    "X_fair_PCA, U, explained_variance = fair_PCA(x_train, n_components=x_train.shape[1], groups=train_groups)\n",
    "x_test_pca = x_test @ U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class imbalance ratio\n",
    "imbalance_ratio = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Set the parameters for XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss',         # Logarithmic loss\n",
    "    'eta': 0.3,                       # Learning rate\n",
    "    'max_depth': 6,                   # Maximum depth of each tree\n",
    "    'min_child_weight': 1,            # Minimum sum of instance weight (Hessian) needed in a child\n",
    "    'subsample': 0.8,                 # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,          # Subsample ratio of columns when constructing each tree\n",
    "    'scale_pos_weight': imbalance_ratio,  # Accounting for class imbalance\n",
    "    'seed': 42                        # Random seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X, y, x_t, y_t, params, rounds):\n",
    "\n",
    "    # Convert your data into DMatrix format\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "    dtest = xgb.DMatrix(x_t, label=y_t)\n",
    "\n",
    "    model = xgb.train(params, dtrain, rounds)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(dtest)\n",
    "\n",
    "    # Convert probabilities to class labels\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_labels)\n",
    "    print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "    # Calculate f1 score\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_labels, average='weighted')\n",
    "    print(\"F1 Score: {:.2f}\".format(f1_score))\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    print(\"ROC AUC: {:.2f}\".format(roc_auc))\n",
    "\n",
    "    # Generate classification report\n",
    "    classification_report = metrics.classification_report(y_test, y_pred_labels)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "F1 Score: 0.73\n",
      "ROC AUC: 0.70\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.52      0.43     17455\n",
      "           1       0.86      0.77      0.81     67287\n",
      "\n",
      "    accuracy                           0.72     84742\n",
      "   macro avg       0.61      0.64      0.62     84742\n",
      "weighted avg       0.76      0.72      0.73     84742\n",
      "\n",
      "Accuracy: 0.69\n",
      "F1 Score: 0.70\n",
      "ROC AUC: 0.63\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.43      0.36     17455\n",
      "           1       0.84      0.75      0.79     67287\n",
      "\n",
      "    accuracy                           0.69     84742\n",
      "   macro avg       0.57      0.59      0.58     84742\n",
      "weighted avg       0.73      0.69      0.70     84742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_xgb(x_train, y_train, x_test, y_test, params, rounds=100)\n",
    "model_fair = train_xgb(X_fair_PCA, y_train, x_test_pca, y_test, params, rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "with open('../models/xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('../models/xgboost_model_fair.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fair, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
